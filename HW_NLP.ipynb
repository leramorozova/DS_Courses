{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7ME-ag0hoDA"
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "eVLBU4s9fF-q",
    "outputId": "3116fcaf-0d65-4c62-c4fa-b1070be5aa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-29 21:13:21--  https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv [переход]\n",
      "--2019-05-29 21:13:22--  https://www.dropbox.com/s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com/cd/0/inline/Ah21DsxdPCpDGcRvEmjX7WQhM6saL_c2Hbk2FS-eJktwRFaC3pO4Ugs0w8zsWnV8nzyqCKxG6zi0TGAsCKa83DseAvEmLF7cf0e1nBU_g-llhA/file# [переход]\n",
      "--2019-05-29 21:13:23--  https://uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com/cd/0/inline/Ah21DsxdPCpDGcRvEmjX7WQhM6saL_c2Hbk2FS-eJktwRFaC3pO4Ugs0w8zsWnV8nzyqCKxG6zi0TGAsCKa83DseAvEmLF7cf0e1nBU_g-llhA/file\n",
      "Распознаётся uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com (uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com)… 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Подключение к uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com (uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com)|162.125.70.6|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 14406837 (14M) [text/plain]\n",
      "Сохранение в: «vk_texts_with_sources.csv»\n",
      "\n",
      "vk_texts_with_sourc 100%[===================>]  13,74M  4,00MB/s    за 3,4s    \n",
      "\n",
      "2019-05-29 21:13:27 (4,00 MB/s) - «vk_texts_with_sources.csv» сохранён [14406837/14406837]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qxZMU8CBK664",
    "outputId": "ad5442ea-27c3-4357-8ab9-6249143c49ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  Начальник Главного оперативного управления Ген...    mil\n",
       "1  Артиллерийские подразделения общевойскового об...    mil\n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil\n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil\n",
       "4  На большом учебно-методическом командирском сб...    mil"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('vk_texts_with_sources.csv', usecols = ['text', 'source'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYNCAr17MFA3"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В этом домашнем задании вы будете решать задачу тематической классификации. Даны тексты, опубликованные в нескольких пабликах VK.com, посвященных государственным и муниципальным службам. Формально задача заключается в том, чтобы по тексту ($d$) определить в каком паблике он опубликован, то есть, к какому классу $c$ он принадлежит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2EnN-U7MemU"
   },
   "source": [
    "## Задание 1 [1 балл]. Описательные статистики\n",
    "Посчитайте:\n",
    "* количество текстов и количество классов\n",
    "* количество слов (без лемматизации и с лемматизацией) в коллекции\n",
    "* среднюю длину текста в словах и символах\n",
    "* найдите 5 самых частых существительных в текстах каждого паблика \n",
    "\n",
    "*Рекомендуем использовать pandas для расчета описательных статистик.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11526</td>\n",
       "      <td>11625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>#СоветМЧС #МЧС #МЧСРОССИИ</td>\n",
       "      <td>mchsgov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>45</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text   source\n",
       "count                       11526    11625\n",
       "unique                      11149        4\n",
       "top     #СоветМЧС #МЧС #МЧСРОССИИ  mchsgov\n",
       "freq                           45     3030"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас 4 класса и 11625 различных текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/valeria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "nltk.download('punkt')\n",
    "mystem_analyzer = Mystem()\n",
    "\n",
    "lemmatized = []\n",
    "unlemmatized = []\n",
    "\n",
    "for doc in df['text']:\n",
    "    text = re.sub(\"<br>\", \"\", str(doc))\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    unlemmatized.append(word_list)\n",
    "    lemmatized.append([mystem_analyzer.lemmatize(word)[0] for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Начальник', 'Главного', 'оперативного', 'управления', 'Генерального', 'штаба', 'Вооруженных', 'Сил', 'РФ', 'генерал-полковник']\n",
      "--------\n",
      "['начальник', 'главный', 'оперативный', 'управление', 'генеральный', 'штаб', 'вооруженный', 'сила', 'рф', 'генерал-полковник']\n"
     ]
    }
   ],
   "source": [
    "print(unlemmatized[0][:10])\n",
    "print(\"--------\")\n",
    "print(lemmatized[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов в датасете: 1163263\n",
      "Количество уникальных лемм: 33153\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "count_unlem = 0\n",
    "\n",
    "for el in unlemmatized:\n",
    "    count_unlem += len(el)\n",
    "\n",
    "cont_lemmatized = list(chain.from_iterable(lemmatized))\n",
    "\n",
    "print(\"Количество токенов в датасете:\", count_unlem)\n",
    "print(\"Количество уникальных лемм:\", len(set(cont_lemmatized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество слов на документ: 100\n",
      "Среднее количество символов на документ: 684\n"
     ]
    }
   ],
   "source": [
    "words_per_doc = np.mean([len(text) for text in unlemmatized])\n",
    "symbols_per_doc = np.mean([len(str(doc)) for doc in df[\"text\"]])\n",
    "\n",
    "print(\"Среднее количество слов на документ:\", int(words_per_doc))\n",
    "print(\"Среднее количество символов на документ:\", int(symbols_per_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "tops = Counter()\n",
    "\n",
    "for i in tqdm(range(len(df['source']))):\n",
    "    for word in range(len(unlemmatized[i])):\n",
    "        if morph.tag(unlemmatized[i][word])[0].POS == 'NOUN':\n",
    "            tops.update([(unlemmatized[i][word], df[\"source\"][i])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTJPlulvQSqQ"
   },
   "source": [
    "Разделите коллекцию текстов на обучающую и тестовую части. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(tops)):\n",
    "#     for el in tops[i].most_common(5):\n",
    "#         print(el)\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yCVYfbpNhXd"
   },
   "source": [
    " ## Задание 2 [2 балла]. Классификация по правилам\n",
    " \n",
    " * Разработайте несколько правил вида \"Если встречается слово $w$, то текст относится к паблику $c$\"\n",
    " * Посчитайте, какую точность, полноту, $f$-меру и $accuracy$ вы получаете при классификации по правилам\n",
    " * Получилось ли у вас придумать правило, которое никогда не ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22tJKQnaOjie"
   },
   "source": [
    "## Задание 3 [3 балла]. Baseline\n",
    "Используйте стандартный ```sklearn.pipeline``` для классификации текстов: \n",
    "* векторизация \n",
    "* $tf-idf$ взвешивание \n",
    "* ваш любимый метод классификации.\n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4m1rDQ3PAqO"
   },
   "source": [
    "## Задание 4 [2 балла]. Снижение размерности\n",
    "Добавьте в ваш ```sklearn.pipeline```  методы снижения размерности:  PCA / LSI / LSA / LDA / другое. Какие методы классификации разумно использовать после снижения размерности? Как изменились результаты классификации после добавления нового шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vVPaaVwPVwg"
   },
   "source": [
    "## Задание 5 [1 балл]. Лемматизация\n",
    "Посмотрите, как влияет лемматизация на качество классификации. Как изменится качество классификации, если вы используете ```CountVectorizer``` на словах или $n$-граммах на лемматизированных текстах?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdakRHahQp-l"
   },
   "source": [
    "## Задание 6 [3 балла]. Continious bag of words\n",
    "Для baseline решения мы использовали обычное представление текста в виде мешка слов. Попробуйте использовать другие модели представления текста – например, в виде непрерывного мешка слов, то есть, в виде набора эмбеддингов. Для того, чтобы получить вектор текста попробуйте:\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст с $tf-idf$ весами\n",
    "* использовать любую модель эмбеддинга документа.\n",
    "\n",
    "Используйте любую модель эмбеддингов по вашему вкусу. \n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyVQ5Gm7Qzcz"
   },
   "source": [
    "## Задание 7 [2 балла]. fastText\n",
    "\n",
    "Используйте ```fastText``` в режиме классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 [4 балла]. CNN\n",
    "\n",
    "Реализуйте модель Kim et al (2014) для решения задачи классификации с помощью CNN. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "Ссылка: Kim Y. Convolutional Neural Networks for Sentence Classification. 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 [4 + 2 балла]. RNN\n",
    "\n",
    "(4 балла)Используйте ```RNN``` (BLSTM с какими-то признаками и пулинг поверх) для решения задачи текстовой классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "\n",
    "За дополнительные 2 балла добавьте в модель символьные признаки - CharCNN или CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 [8 баллов]. ULMFit\n",
    "\n",
    "Используйте ```ULMFit``` для решения задачи классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fKqCD6Q5tW"
   },
   "source": [
    "## Конец\n",
    "Выполните какие-то из предыдущих заданий. Для всех заданий, кроме задания 1 требуется вычислить метрику accuracy метода.\n",
    "\n",
    "Подведите итоги и проведите сравнение всех использованных методов. Какой из них показался вам лучше и почему?\n",
    "\n",
    "**NB!** Задание обязательное вне зависимости от того, сколько из предыдущих пунктов вы выполнили, и дополнительных баллов не дает.\n",
    "\n",
    "\n",
    "Для получения полной оценки за NLP-часть достаточно набрать **20 баллов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FkOuR_NiXeT"
   },
   "source": [
    "# Правила сдачи \n",
    "\n",
    "1. Домашняя работа должна быть выполнена в ipynb-тетрадке.\n",
    "2. Сделанную тетрадку нужно отправить ассистенту (ссылка на контакты будет в вики).\n",
    "3. Задание выполняется индивидуально.\n",
    "4. Все вычисления должны быть снабжены пояснениями!\n",
    "5. Дедлайн – 10 июня в 10.00.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
