{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E7ME-ag0hoDA"
   },
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "eVLBU4s9fF-q",
    "outputId": "3116fcaf-0d65-4c62-c4fa-b1070be5aa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-05-29 21:13:21--  https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Распознаётся www.dropbox.com (www.dropbox.com)… 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Подключение к www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 301 Moved Permanently\n",
      "Адрес: /s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv [переход]\n",
      "--2019-05-29 21:13:22--  https://www.dropbox.com/s/raw/nd7v1fod89xla6j/vk_texts_with_sources.csv\n",
      "Повторное использование соединения с www.dropbox.com:443.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com/cd/0/inline/Ah21DsxdPCpDGcRvEmjX7WQhM6saL_c2Hbk2FS-eJktwRFaC3pO4Ugs0w8zsWnV8nzyqCKxG6zi0TGAsCKa83DseAvEmLF7cf0e1nBU_g-llhA/file# [переход]\n",
      "--2019-05-29 21:13:23--  https://uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com/cd/0/inline/Ah21DsxdPCpDGcRvEmjX7WQhM6saL_c2Hbk2FS-eJktwRFaC3pO4Ugs0w8zsWnV8nzyqCKxG6zi0TGAsCKa83DseAvEmLF7cf0e1nBU_g-llhA/file\n",
      "Распознаётся uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com (uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com)… 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Подключение к uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com (uca976fd562c538cb46e54f99031.dl.dropboxusercontent.com)|162.125.70.6|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 14406837 (14M) [text/plain]\n",
      "Сохранение в: «vk_texts_with_sources.csv»\n",
      "\n",
      "vk_texts_with_sourc 100%[===================>]  13,74M  4,00MB/s    за 3,4s    \n",
      "\n",
      "2019-05-29 21:13:27 (4,00 MB/s) - «vk_texts_with_sources.csv» сохранён [14406837/14406837]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/nd7v1fod89xla6j/vk_texts_with_sources.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "qxZMU8CBK664",
    "outputId": "ad5442ea-27c3-4357-8ab9-6249143c49ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source\n",
       "0  Начальник Главного оперативного управления Ген...    mil\n",
       "1  Артиллерийские подразделения общевойскового об...    mil\n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil\n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil\n",
       "4  На большом учебно-методическом командирском сб...    mil"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('vk_texts_with_sources.csv', usecols = ['text', 'source'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYNCAr17MFA3"
   },
   "source": [
    "# Домашнее задание\n",
    "\n",
    "В этом домашнем задании вы будете решать задачу тематической классификации. Даны тексты, опубликованные в нескольких пабликах VK.com, посвященных государственным и муниципальным службам. Формально задача заключается в том, чтобы по тексту ($d$) определить в каком паблике он опубликован, то есть, к какому классу $c$ он принадлежит. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2EnN-U7MemU"
   },
   "source": [
    "## Задание 1 [1 балл]. Описательные статистики\n",
    "Посчитайте:\n",
    "* количество текстов и количество классов\n",
    "* количество слов (без лемматизации и с лемматизацией) в коллекции\n",
    "* среднюю длину текста в словах и символах\n",
    "* найдите 5 самых частых существительных в текстах каждого паблика \n",
    "\n",
    "*Рекомендуем использовать pandas для расчета описательных статистик.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11526</td>\n",
       "      <td>11625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11149</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>#СоветМЧС #МЧС #МЧСРОССИИ</td>\n",
       "      <td>mil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>45</td>\n",
       "      <td>3030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             text source\n",
       "count                       11526  11625\n",
       "unique                      11149      4\n",
       "top     #СоветМЧС #МЧС #МЧСРОССИИ    mil\n",
       "freq                           45   3030"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас 4 класса и 11625 различных текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/valeria/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "nltk.download('punkt')\n",
    "mystem_analyzer = Mystem()\n",
    "\n",
    "lemmatized = []\n",
    "unlemmatized = []\n",
    "\n",
    "for doc in df['text']:\n",
    "    text = re.sub(\"<br>\", \"\", str(doc))\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    unlemmatized.append(word_list)\n",
    "    lemmatized.append([mystem_analyzer.lemmatize(word)[0] for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Начальник', 'Главного', 'оперативного', 'управления', 'Генерального', 'штаба', 'Вооруженных', 'Сил', 'РФ', 'генерал-полковник']\n",
      "--------\n",
      "['начальник', 'главный', 'оперативный', 'управление', 'генеральный', 'штаб', 'вооруженный', 'сила', 'рф', 'генерал-полковник']\n"
     ]
    }
   ],
   "source": [
    "print(unlemmatized[0][:10])\n",
    "print(\"--------\")\n",
    "print(lemmatized[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токенов в датасете: 1163263\n",
      "Количество уникальных лемм: 33153\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "count_unlem = 0\n",
    "\n",
    "for el in unlemmatized:\n",
    "    count_unlem += len(el)\n",
    "\n",
    "cont_lemmatized = list(chain.from_iterable(lemmatized))\n",
    "\n",
    "print(\"Количество токенов в датасете:\", count_unlem)\n",
    "print(\"Количество уникальных лемм:\", len(set(cont_lemmatized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее количество слов на документ: 100\n",
      "Среднее количество символов на документ: 684\n"
     ]
    }
   ],
   "source": [
    "words_per_doc = np.mean([len(text) for text in unlemmatized])\n",
    "symbols_per_doc = np.mean([len(str(doc)) for doc in df[\"text\"]])\n",
    "\n",
    "print(\"Среднее количество слов на документ:\", int(words_per_doc))\n",
    "print(\"Среднее количество символов на документ:\", int(symbols_per_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11625/11625 [03:08<00:00, 61.53it/s]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from tqdm import tqdm\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "\n",
    "tops = Counter()\n",
    "\n",
    "for i in tqdm(range(len(df['source']))):\n",
    "    for word in range(len(unlemmatized[i])):\n",
    "        if morph.tag(unlemmatized[i][word])[0].POS == 'NOUN':\n",
    "            tops.update([(unlemmatized[i][word], df[\"source\"][i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для сообщества mil наиболее частотны\n",
      "Минобороны 1813\n",
      "России 1179\n",
      "обороны 799\n",
      "военного 736\n",
      "ходе 697\n",
      "\n",
      "\n",
      "Для сообщества mchsgov наиболее частотны\n",
      "МЧС 3486\n",
      "России 1588\n",
      "МЧСРОССИИ 1226\n",
      "безопасности 342\n",
      "БудниМЧС 258\n",
      "\n",
      "\n",
      "Для сообщества russianpost наиболее частотны\n",
      "России 2535\n",
      "Почты 1130\n",
      "ПочтаРоссии 936\n",
      "Почта 826\n",
      "года 678\n",
      "\n",
      "\n",
      "Для сообщества mospolice наиболее частотны\n",
      "МВД 4947\n",
      "России 3890\n",
      "полиции 2977\n",
      "Москве 2674\n",
      "полиция 2616\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns = {}\n",
    "\n",
    "for key in tops:\n",
    "    if key[1] not in nouns:\n",
    "        nouns[key[1]] = [(key[0], tops[key])]\n",
    "    else:\n",
    "        nouns[key[1]].append((key[0], tops[key]))\n",
    "\n",
    "most_common = {key : sorted([el[1] for el in nouns[key]], reverse=True)[:5] for key in nouns}\n",
    "\n",
    "for key in most_common:\n",
    "    print(\"Для сообщества\", key, \"наиболее частотны\")\n",
    "    for el in most_common[key]:\n",
    "        for e in nouns[key]:\n",
    "            if e[1] == el:\n",
    "                print(e[0], el)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm2\n",
    "\n",
    "pmm = pm2.MorphAnalyzer()\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "# сюда добавить парсинг получше\n",
    "def parse(text):\n",
    "    text = re.sub(r'[^\\w\\s]','', str(text))\n",
    "    text = re.sub(\"[0-9A-Za-z#_=]\", \"\", text)\n",
    "    text = [pmm.normal_forms(x)[0] for x in text.split() if x not in russian_stopwords]\n",
    "    if text == [np.nan]:\n",
    "        return(['nan'])\n",
    "    return text\n",
    "\n",
    "df['lemmatized'] = df['text'].apply(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlem_parse(text):\n",
    "    text = re.sub(r'[^\\w\\s]','', str(text))\n",
    "    text = re.sub(\"[0-9A-Za-z#_=]\", \"\", text)\n",
    "    text = [x.lower() for x in text.split() if x not in russian_stopwords]\n",
    "    if text == [np.nan]:\n",
    "        return(['nan'])\n",
    "    return text\n",
    "\n",
    "df['unlemmatized'] = df['text'].apply(unlem_parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word_length</th>\n",
       "      <th>unlemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[начальник, главный, оперативный, управление, ...</td>\n",
       "      <td>1257</td>\n",
       "      <td>[начальник, главного, оперативного, управления...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[артиллерийский, подразделение, общевойсковой,...</td>\n",
       "      <td>67</td>\n",
       "      <td>[артиллерийские, подразделения, общевойскового...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[подразделение, морской, пехота, каспийский, ф...</td>\n",
       "      <td>38</td>\n",
       "      <td>[подразделения, морской, пехоты, каспийской, ф...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[команда, всеармейский, этап, конкурс, арми, т...</td>\n",
       "      <td>100</td>\n",
       "      <td>[команды, всеармейских, этапах, конкурсов, арм...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[на, большой, учебнометодический, командирский...</td>\n",
       "      <td>63</td>\n",
       "      <td>[на, большом, учебнометодическом, командирском...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source  \\\n",
       "0  Начальник Главного оперативного управления Ген...    mil   \n",
       "1  Артиллерийские подразделения общевойскового об...    mil   \n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil   \n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil   \n",
       "4  На большом учебно-методическом командирском сб...    mil   \n",
       "\n",
       "                                          lemmatized  word_length  \\\n",
       "0  [начальник, главный, оперативный, управление, ...         1257   \n",
       "1  [артиллерийский, подразделение, общевойсковой,...           67   \n",
       "2  [подразделение, морской, пехота, каспийский, ф...           38   \n",
       "3  [команда, всеармейский, этап, конкурс, арми, т...          100   \n",
       "4  [на, большой, учебнометодический, командирский...           63   \n",
       "\n",
       "                                        unlemmatized  \n",
       "0  [начальник, главного, оперативного, управления...  \n",
       "1  [артиллерийские, подразделения, общевойскового...  \n",
       "2  [подразделения, морской, пехоты, каспийской, ф...  \n",
       "3  [команды, всеармейских, этапах, конкурсов, арм...  \n",
       "4  [на, большом, учебнометодическом, командирском...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Начальник Главного оперативного управления Ген...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[начальник, главный, оперативный, управление, ...</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Артиллерийские подразделения общевойскового об...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[артиллерийский, подразделение, общевойсковой,...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Подразделения морской пехоты Каспийской флотил...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[подразделение, морской, пехота, каспийский, ф...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Команды на всеармейских этапах конкурсов АрМИ-...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[команда, всеармейский, этап, конкурс, арми, т...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>На большом учебно-методическом командирском сб...</td>\n",
       "      <td>mil</td>\n",
       "      <td>[на, большой, учебнометодический, командирский...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text source  \\\n",
       "0  Начальник Главного оперативного управления Ген...    mil   \n",
       "1  Артиллерийские подразделения общевойскового об...    mil   \n",
       "2  Подразделения морской пехоты Каспийской флотил...    mil   \n",
       "3  Команды на всеармейских этапах конкурсов АрМИ-...    mil   \n",
       "4  На большом учебно-методическом командирском сб...    mil   \n",
       "\n",
       "                                          lemmatized  word_length  \n",
       "0  [начальник, главный, оперативный, управление, ...         1257  \n",
       "1  [артиллерийский, подразделение, общевойсковой,...           67  \n",
       "2  [подразделение, морской, пехота, каспийский, ф...           38  \n",
       "3  [команда, всеармейский, этап, конкурс, арми, т...          100  \n",
       "4  [на, большой, учебнометодический, командирский...           63  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_length'] = pd.Series([len(doc) for doc in df[\"lemmatized\"]], index=df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "id_source = {'mchsgov': 0,\n",
    "             'mil': 1,\n",
    "             'mospolice': 2,\n",
    "             'russianpost': 3}\n",
    "\n",
    "X = df.drop(columns=['source'])\n",
    "y = [id_source[el] for el in df[\"source\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yCVYfbpNhXd"
   },
   "source": [
    " ## Задание 2 [2 балла]. Классификация по правилам\n",
    " \n",
    " * Разработайте несколько правил вида \"Если встречается слово $w$, то текст относится к паблику $c$\"\n",
    " * Посчитайте, какую точность, полноту, $f$-меру и $accuracy$ вы получаете при классификации по правилам\n",
    " * Получилось ли у вас придумать правило, которое никогда не ошибается?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTJPlulvQSqQ"
   },
   "source": [
    "Разделите коллекцию текстов на обучающую и тестовую части. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in df[\"text\"]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22tJKQnaOjie"
   },
   "source": [
    "## Задание 3 [3 балла]. Baseline\n",
    "Используйте стандартный ```sklearn.pipeline``` для классификации текстов: \n",
    "* векторизация \n",
    "* $tf-idf$ взвешивание \n",
    "* ваш любимый метод классификации.\n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4m1rDQ3PAqO"
   },
   "source": [
    "## Задание 4 [2 балла]. Снижение размерности\n",
    "Добавьте в ваш ```sklearn.pipeline```  методы снижения размерности:  PCA / LSI / LSA / LDA / другое. Какие методы классификации разумно использовать после снижения размерности? Как изменились результаты классификации после добавления нового шага?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7vVPaaVwPVwg"
   },
   "source": [
    "## Задание 5 [1 балл]. Лемматизация\n",
    "Посмотрите, как влияет лемматизация на качество классификации. Как изменится качество классификации, если вы используете ```CountVectorizer``` на словах или $n$-граммах на лемматизированных текстах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#хотя бы досюда включительно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cdakRHahQp-l"
   },
   "source": [
    "## Задание 6 [3 балла]. Continious bag of words\n",
    "Для baseline решения мы использовали обычное представление текста в виде мешка слов. Попробуйте использовать другие модели представления текста – например, в виде непрерывного мешка слов, то есть, в виде набора эмбеддингов. Для того, чтобы получить вектор текста попробуйте:\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст\n",
    "* усреднить все эмбеддинги слов, входящих в этот текст с $tf-idf$ весами\n",
    "* использовать любую модель эмбеддинга документа.\n",
    "\n",
    "Используйте любую модель эмбеддингов по вашему вкусу. \n",
    "\n",
    "\n",
    "Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uyVQ5Gm7Qzcz"
   },
   "source": [
    "## Задание 7 [2 балла]. fastText\n",
    "\n",
    "Используйте ```fastText``` в режиме классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 [4 балла]. CNN\n",
    "\n",
    "Реализуйте модель Kim et al (2014) для решения задачи классификации с помощью CNN. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "Ссылка: Kim Y. Convolutional Neural Networks for Sentence Classification. 2014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 [4 + 2 балла]. RNN\n",
    "\n",
    "(4 балла)Используйте ```RNN``` (BLSTM с какими-то признаками и пулинг поверх) для решения задачи текстовой классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix).\n",
    "\n",
    "За дополнительные 2 балла добавьте в модель символьные признаки - CharCNN или CharRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 [8 баллов]. ULMFit\n",
    "\n",
    "Используйте ```ULMFit``` для решения задачи классификации. Оцените результаты классификации по стандартным мерам качества и проведите анализ ошибок. Для этого рекомендуем визуализировать матрицу ошибок (confusion matrix). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_8fKqCD6Q5tW"
   },
   "source": [
    "## Конец\n",
    "Выполните какие-то из предыдущих заданий. Для всех заданий, кроме задания 1 требуется вычислить метрику accuracy метода.\n",
    "\n",
    "Подведите итоги и проведите сравнение всех использованных методов. Какой из них показался вам лучше и почему?\n",
    "\n",
    "**NB!** Задание обязательное вне зависимости от того, сколько из предыдущих пунктов вы выполнили, и дополнительных баллов не дает.\n",
    "\n",
    "\n",
    "Для получения полной оценки за NLP-часть достаточно набрать **20 баллов**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FkOuR_NiXeT"
   },
   "source": [
    "# Правила сдачи \n",
    "\n",
    "1. Домашняя работа должна быть выполнена в ipynb-тетрадке.\n",
    "2. Сделанную тетрадку нужно отправить ассистенту (ссылка на контакты будет в вики).\n",
    "3. Задание выполняется индивидуально.\n",
    "4. Все вычисления должны быть снабжены пояснениями!\n",
    "5. Дедлайн – 10 июня в 10.00.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
