{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "- улучшить парсер (убрать пустые тексты)\n",
    "- убрать наны из текстов!!!!\n",
    "- выкинуть некириллицу\n",
    "- возьмем обученные эмбеддинги у Гали\n",
    "- tf-idf\n",
    "\n",
    "## Метрики\n",
    "длина текста, max min tf-idf, лемматизированные тексты, max и min косинусное расстояние между парами слов (соседних и не соседних, если успеем посчитать), tf-idf взвешенное (умножать каждое слово на tf-idf этого слова для этого документа), слово с самым высоким tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "H0Epx-f8LqGR",
    "outputId": "b597bf3a-3f85-44d2-ab43-e64575122d4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Мама ))</td>\n",
       "      <td>telegony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>Желаем вам счастья и света в душе!</td>\n",
       "      <td>telegony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>КУДАХ И ВСЁ СТРАННО\\r\\n\\r\\nкудах ухарашивал ги...</td>\n",
       "      <td>kudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>ОБЫЧНЫЙ ДЕНЬ У КУДАХА\\r\\n\\r\\n..а как ещё заста...</td>\n",
       "      <td>kudah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Вполне возможно, что собравшись на днях в мага...</td>\n",
       "      <td>podkoren</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text     group\n",
       "id                                                               \n",
       "1271                                            Мама ))  telegony\n",
       "1325                 Желаем вам счастья и света в душе!  telegony\n",
       "2993  КУДАХ И ВСЁ СТРАННО\\r\\n\\r\\nкудах ухарашивал ги...     kudah\n",
       "2919  ОБЫЧНЫЙ ДЕНЬ У КУДАХА\\r\\n\\r\\n..а как ещё заста...     kudah\n",
       "453   Вполне возможно, что собравшись на днях в мага...  podkoren"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "df = pd.read_csv('data.csv', index_col='id')\n",
    "df = df.sample(frac=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaA-XZZ_-myv"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "DXC3AW1V_zNr",
    "outputId": "df51260e-f0c8-470a-e220-9b7b6d98e701"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2447</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2429</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Доброе утро!</td>\n",
       "      <td>krishnaits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                text       group\n",
       "count           2447        3000\n",
       "unique          2429           5\n",
       "top     Доброе утро!  krishnaits\n",
       "freq               5         600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=[np.object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "hCyF9ATDAAwg",
    "outputId": "013c715c-6bb5-4f2d-bf7a-a465933cc855"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LGPC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "nltk.download('punkt')\n",
    "mystem_analyzer = Mystem()\n",
    "\n",
    "lemmatized = []\n",
    "unlemmatized = []\n",
    "\n",
    "for doc in df['text']:\n",
    "    text = re.sub(\"<br>\", \"\", str(doc))\n",
    "    word_list = nltk.word_tokenize(text)\n",
    "    unlemmatized.append(word_list)\n",
    "    lemmatized.append([mystem_analyzer.lemmatize(word)[0] for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csNWujUCAG-U"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "count_unlem = 0\n",
    "\n",
    "for el in unlemmatized:\n",
    "    count_unlem += len(el)\n",
    "\n",
    "cont_lemmatized = list(chain.from_iterable(lemmatized))\n",
    "\n",
    "print(\"Количество токенов в датасете:\", count_unlem)\n",
    "print(\"Количество уникальных лемм:\", len(set(cont_lemmatized)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8ZSjGM-AH0u"
   },
   "outputs": [],
   "source": [
    "words_per_doc = np.mean([len(text) for text in unlemmatized])\n",
    "symbols_per_doc = np.mean([len(str(doc)) for doc in df[\"text\"]])\n",
    "\n",
    "print(\"Среднее количество слов на документ:\", int(words_per_doc))\n",
    "print(\"Среднее количество символов на документ:\", int(symbols_per_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pymorphy2 as pm2\n",
    "\n",
    "pmm = pm2.MorphAnalyzer()\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "# сюда добавить парсинг получше\n",
    "def parse(text):\n",
    "    text = re.sub(r'[^\\w\\s]','', str(text))\n",
    "    text = re.sub(\"[0-9A-Za-z#_]\", \"\", text)\n",
    "    text = [pmm.normal_forms(x)[0] for x in text.split() if x not in russian_stopwords]\n",
    "    if text == [np.nan]:\n",
    "        return(['nan'])\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(parse)\n",
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, row in df.iterrows():\n",
    "#     if row['text'] == []:\n",
    "#         df = df.drop(index=idx)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reindex(index=range(len(df)))\n",
    "cross_val_folds = []\n",
    "\n",
    "fold = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    fold.append(row)\n",
    "    if idx % (len(df) // 10) == 0:\n",
    "        cross_val_folds.append(fold)\n",
    "        fold = []\n",
    "\n",
    "len(cross_val_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "cross_val_folds = cross_val_folds[1:]\n",
    "\n",
    "for fold in cross_val_folds:\n",
    "    print(len(fold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "dct = Dictionary()\n",
    "#for text in lemmatized_corpus:\n",
    "dct.add_documents(df[\"text\"])\n",
    "corpus = []\n",
    "for idx, row in df.iterrows():\n",
    "    corpus.append(dct.doc2bow(row['text']))\n",
    "idfs = {}\n",
    "tf_idf = TfidfModel(corpus)\n",
    "for key in dct:\n",
    "    try:\n",
    "        idfs[dct[key]] = tf_idf.idfs[key]\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.36221007863501486),\n",
       " (1, 0.1467250140965477),\n",
       " (2, 0.41541282888806597),\n",
       " (3, 0.42624121900071205),\n",
       " (4, 0.26131078311247774),\n",
       " (5, 0.3324372938635929),\n",
       " (6, 0.35322561348812204),\n",
       " (7, 0.2531146050432289),\n",
       " (8, 0.24608396493680115),\n",
       " (9, 0.2546285513490461)]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = tf_idf[corpus[0][:10]]\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Показательная фотокарточка.',\n",
       " 'Бойцы «IFB» (интернациональный левый «батальон» в составе курдских «SDF») вывесили над Раккой, бывшей столицей Исламского Государства, красный советский флаг.',\n",
       " 'Мол, советские войска спасли мир от фашизма, освободив Берлин, а мы, продолжатели левого дела, спасли мир от «ИГ».',\n",
       " 'Несоответствие в том, что, по правде говоря, вывешивать над Раккой надо было американский флаг, ибо американская авиация, артиллерия, бронетехника, пехота как раз и обеспечили курдам их «левую» победу.',\n",
       " 'Вплоть до бомбёжек со стратегов B-1 и того, что американский спецназ гонял с шевронами антикапиталистической «YPG».',\n",
       " 'Без этой помощи курдов добили бы ещё в Кобани осенью 2014 года.',\n",
       " 'Но левых пользователей из «IFB» не смущает колоссальная поддержка мощнейшей капиталистической страны, которая в ХХ веке делала всё возможное, чтобы уничтожить «социалистические» государства и движения.',\n",
       " 'Главное, что у нас есть красный флаг.',\n",
       " 'Как-то так и выглядит состояние послемодерна: картинка важнее смысла; повторение воспроизводит форму, а не ситуацию; символ становится содержанием; немногочисленная группка разрастается в целый батальон.',\n",
       " 'А в мире всё остаётся по-прежнему.',\n",
       " '#ПК_мысли']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = pd.read_csv('data.csv', index_col='id')\n",
    "df_split = df_split.sample(frac=1)\n",
    "\n",
    "def sent_split(text):\n",
    "    sents = nltk.sent_tokenize(str(text))\n",
    "    return sents\n",
    "\n",
    "df_split['text'] = df_split['text'].apply(sent_split)\n",
    "df_split[\"text\"][20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "premodel = Word2Vec(sentences, min_count = 1, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Project_sect.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
